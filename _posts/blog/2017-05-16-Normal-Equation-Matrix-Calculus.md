---
layout: post
title: Normal Equation and Matrix Calculus
excerpt: "Overcome the fear of doing matrix calculus."
modified: 2017-05-16T14:17:25-04:00
categories: blog
tags: [Machine Learning]
image:
  feature: site_logos/Logo Umbrella_Corporation.png
  credit: 
  creditlink: 
comments: true
share: true
---

I thinking I am remedying some of the missing points on my way studying machine learning in these days.

I clearly remember that when I was taking the MOOC linear regression courses, the professors did not mention too much about how to work on the derivatives of the loss function. One might simply take scalar values, instead of matrix, as an illustration of that the derivative is correct, without providing sufficient information on how to do the derivatives by hand. I have been using deep learning tools which could calculate the derivatives automatically, such as TensorFlow, for a while. I kind got used to living without doing "hard math". But somehow, I came across with the normal equation for the linear regression least-squared sum loss function, today. I have to honestly tell you that I had no idea how to calculate the derivatives for it, though my college Calculus and Linear Algebra were quite good.

I then tried to look up some materials online, and I did find [one](http://eli.thegreenplace.net/2015/the-normal-equation-and-matrix-calculus/#id4). In case the link expires, you may also download the pdf [here](/downloads/blog/2017-05-16-Normal-Equation-Matrix-Calculus/Normal_Equation_Matrix_Calculus.pdf).

The author also tried to relieve us that it is totally ok if you are not sure about how to do these stuff. Working on these requires sufficient amount of training, just like what we used to study the basic calculus. 

The matrix calculus priciples could be found [here](https://en.wikipedia.org/wiki/Matrix_calculus), which is extremely crazy to me.
